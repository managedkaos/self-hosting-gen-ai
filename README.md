# From Laptop to Cloud: Self-Hosting Gen AI for Privacy and Performance

## The Rise of Generative Artificial Intelligence and Private Foundation Models

## Privacy Needs for Individuals and Businesses

## Glossary of Terms
- GPT: generative pre-trained transformer
- Token: the smallest unit of text used in processing prompts and generating repsonses; consider a token to be ~4 characters
- Latency (ms): The amount of time the FM uses to generate each token in a sequence
- Input token count: The number of input tokens used by the FM during inference.
- Output token count: The number of tokens generated in a response by the FM.
- Tokens per second: The rate at which the model is able to generate a response
- Time to first token: The amount of time between the client's request being received and the first token sent in response

## The Introduction of Public Foundation Models

### Researching Models
- Ollama Model Library
- Parameters
- Sizes

### Model Playgrounds
- Cloudflare
- [Caylent Battleground](https://battleground.caylent.com/chat)

## Ollama and Open Web UI

### Pros and Upsides
### Cons and Downsides

## Installing Ollama and Open Web UI on a Laptop _(With Demonstration)_

### Hardware and Operating System Requirements
- CPU/GPU, RAM, and Disk
- Mac
- Windows
- Linux


## Installing Ollama and Openeb Web UI on a Cloud Server _(With Demonstration)_

### Hardware and Operating System Requirements
- CPU/GPU, RAM, and Disk
- LInux
- AMI Selection
- Costs

## Advanced Hosting in the Cloud _(With Demonstration)_

### Hardware and Operating System Requirements
- CPU/GPU, RAM, and Disk
- LInux
- AMI Selection
- Multiple Servers (For high availability and advanced model support)
- Hosted Zone
- SSL Certificates
- Costs
